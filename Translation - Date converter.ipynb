{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Converter\n",
    "\n",
    "We will be translating from one date format to another. In order to do this we need to connect two set of LSTMs (RNNs). The diagram looks as follows: Each set respectively sharing weights (i.e. each of the 4 green cells have the same weights and similarly with the blue cells). The first is a many to one LSTM, which summarises the question at the last hidden layer (and cell memory).\n",
    "\n",
    "The second set (blue) is a Many to Many LSTM which has different weights to the first set of LSTMs. The input is simply the answer sentence while the output is the same sentence shifted by one. Ofcourse during testing time there are no inputs for the `answer` and is only used during training.\n",
    "![seq2seq_diagram](https://i.stack.imgur.com/YjlBt.png) \n",
    "\n",
    "**20th January 2017 => 20th January 2009**\n",
    "![troll](./images/troll_face.png)\n",
    "\n",
    "## References:\n",
    "1. https://github.com/ematvey/tensorflow-seq2seq-tutorials/blob/master/1-seq2seq.ipynb\n",
    "2. The generation process was taken from: https://github.com/datalogue/keras-attention/blob/master/data/generate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in /root/miniconda3/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: babel in /root/miniconda3/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: email-validator==1.0.2 in /root/miniconda3/lib/python3.6/site-packages (from faker)\r\n",
      "Requirement already satisfied: six in /root/miniconda3/lib/python3.6/site-packages (from faker)\r\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /root/miniconda3/lib/python3.6/site-packages (from faker)\r\n",
      "Requirement already satisfied: pytz>=0a in /root/miniconda3/lib/python3.6/site-packages (from babel)\r\n",
      "Requirement already satisfied: dnspython>=1.15.0 in /root/miniconda3/lib/python3.6/site-packages (from email-validator==1.0.2->faker)\r\n",
      "Requirement already satisfied: idna>=2.0.0 in /root/miniconda3/lib/python3.6/site-packages (from email-validator==1.0.2->faker)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install faker babel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "from faker import Faker\n",
    "import babel\n",
    "from babel.dates import format_date\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding\n",
    "\n",
    "import tensorflow.contrib.legacy_seq2seq as seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "fake.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "FORMATS = ['short',\n",
    "           'medium',\n",
    "           'long',\n",
    "           'full',\n",
    "           'd MMM YYY',\n",
    "           'd MMMM YYY',\n",
    "           'dd MMM YYY',\n",
    "           'd MMM, YYY',\n",
    "           'd MMMM, YYY',\n",
    "           'dd, MMM YYY',\n",
    "           'd MM YY',\n",
    "           'd MMMM YYY',\n",
    "           'MMMM d YYY',\n",
    "           'MMMM d, YYY',\n",
    "           'dd.MM.YY',\n",
    "           ]\n",
    "\n",
    "# change this if you want it to work with only a single language\n",
    "LOCALES = babel.localedata.locale_identifiers()\n",
    "LOCALES = [lang for lang in LOCALES if 'en' in str(lang)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_date():\n",
    "    \"\"\"\n",
    "        Creates some fake dates \n",
    "        :returns: tuple containing \n",
    "                  1. human formatted string\n",
    "                  2. machine formatted string\n",
    "                  3. date object.\n",
    "    \"\"\"\n",
    "    dt = fake.date_object()\n",
    "\n",
    "    # wrapping this in a try catch because\n",
    "    # the locale 'vo' and format 'full' will fail\n",
    "    try:\n",
    "        human = format_date(dt,\n",
    "                            format=random.choice(FORMATS),\n",
    "                            locale=random.choice(LOCALES))\n",
    "\n",
    "        case_change = random.randint(0,3) # 1/2 chance of case change\n",
    "        if case_change == 1:\n",
    "            human = human.upper()\n",
    "        elif case_change == 2:\n",
    "            human = human.lower()\n",
    "\n",
    "        machine = dt.isoformat()\n",
    "    except AttributeError as e:\n",
    "        return None, None, None\n",
    "\n",
    "    return human, machine #, dt\n",
    "\n",
    "data = [create_date() for _ in range(50000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7 07 13', '2013-07-07'),\n",
       " ('30 JULY 1977', '1977-07-30'),\n",
       " ('Tuesday, September 14, 1971', '1971-09-14'),\n",
       " ('18 09 88', '1988-09-18'),\n",
       " ('31, Aug 1986', '1986-08-31')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [x for x, y in data]\n",
    "y = [y for x, y in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_characters = set(' '.join(x))\n",
    "char2numX = dict(zip(u_characters, range(len(u_characters))))\n",
    "\n",
    "u_characters = set(' '.join(y))\n",
    "char2numY = dict(zip(u_characters, range(len(u_characters))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad all sequences that are shorter than the max length of the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>31, Aug 1986'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2numX['<PAD>'] = len(char2numX)\n",
    "num2charX = dict(zip(char2numX.values(), char2numX.keys()))\n",
    "max_len = max([len(date) for date in x])\n",
    "\n",
    "x = [[char2numX['<PAD>']]*(max_len - len(date)) +[char2num[x_] for x_ in date] for date in x]\n",
    "''.join([num2charX[x_] for x_ in x[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<GO>1986-08-31'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2numY['<GO>'] = len(char2numY)\n",
    "num2charY = dict(zip(char2numY.values(), char2numY.keys()))\n",
    "\n",
    "y = [[char2numY['<GO>']] + [char2numY[y_] for y_ in date] for date in y]\n",
    "''.join([num2charY[y_] for y_ in y[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_seq_length = len(x[0])\n",
    "y_seq_length = len(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_inp = [tf.placeholder(tf.int32, shape=(None,),\n",
    "           name=\"inp%i\" % t) for t in range(x_seq_length)]\n",
    "\n",
    "labels = [tf.placeholder(tf.int32, shape=(None,),\n",
    "            name=\"labels%i\" % t) for t in range(y_seq_length)]\n",
    "\n",
    "weights = [tf.ones_like(labels_t, dtype=tf.float32)\n",
    "           for labels_t in labels]\n",
    "\n",
    "# Decoder input: prepend some \"GO\" token and drop the final\n",
    "# token of the encoder input\n",
    "dec_inp = ([tf.zeros_like(enc_inp[0], dtype=np.int32, name=\"GO\")] + enc_inp[:-1])\n",
    "\n",
    "is_train  = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Lengths of logits, weights, and targets must be the same 29, 11, 11.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-59e48f0166c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                         feed_previous = tf.logical_not(is_train))\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\u001b[0m in \u001b[0;36msequence_loss\u001b[0;34m(logits, targets, weights, average_across_timesteps, average_across_batch, softmax_loss_function, name)\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0maverage_across_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage_across_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             softmax_loss_function=softmax_loss_function))\n\u001b[0m\u001b[1;32m   1132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage_across_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m       \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\u001b[0m in \u001b[0;36msequence_loss_by_example\u001b[0;34m(logits, targets, weights, average_across_timesteps, softmax_loss_function, name)\u001b[0m\n\u001b[1;32m   1073\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     raise ValueError(\"Lengths of logits, weights, and targets must be the same \"\n\u001b[0;32m-> 1075\u001b[0;31m                      \"%d, %d, %d.\" % (len(logits), len(weights), len(targets)))\n\u001b[0m\u001b[1;32m   1076\u001b[0m   with ops.name_scope(name, \"sequence_loss_by_example\",\n\u001b[1;32m   1077\u001b[0m                       logits + targets + weights):\n",
      "\u001b[0;31mValueError\u001b[0m: Lengths of logits, weights, and targets must be the same 29, 11, 11."
     ]
    }
   ],
   "source": [
    "memory_dim = 32\n",
    "embed_dim = 32\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(memory_dim)\n",
    "dec_outputs, dec_memory = seq2seq.embedding_rnn_seq2seq(enc_inp, dec_inp, cell, \n",
    "                                                        len(char2numX), len(char2numY), \n",
    "                                                        embed_dim,\n",
    "                                                        feed_previous = tf.logical_not(is_train))\n",
    "\n",
    "loss = seq2seq.sequence_loss(dec_outputs, labels, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
