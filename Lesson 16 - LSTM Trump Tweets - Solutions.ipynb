{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM (Long Short Term Memory)\n",
    "\n",
    "There is a branch of Deep Learning that is dedicated to processing time series. These deep Nets are **Recursive Neural Nets (RNNs)**. LSTMs are one of the few types of RNNs that are available. Gated Recurent Units (GRUs) are the other type of popular RNNs.\n",
    "\n",
    "This is an illustration from http://colah.github.io/posts/2015-08-Understanding-LSTMs/ (A highly recommended read)\n",
    "\n",
    "![RNNs](./RNN-unrolled.png)\n",
    "\n",
    "Pros:\n",
    "- Really powerful pattern recognition system for time series\n",
    "\n",
    "Cons:\n",
    "- Cannot deal with missing time steps.\n",
    "- Time steps must be discretised and not continuous.\n",
    "\n",
    "![trump](./images/trump.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, LSTM, Embedding, TimeDistributed\n",
    "from keras.models import load_model, model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chr2val(ch):\n",
    "    ch = ch.lower()\n",
    "    if ch.isalpha():\n",
    "        return 1 + (ord(ch) - ord('a'))\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def val2chr(v):\n",
    "    if v == 0:\n",
    "        return ' '\n",
    "    else:\n",
    "        return chr(ord('a') + v - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>i think senator blumenthal should take a nice ...</td>\n",
       "      <td>08-07-2017 20:48:54</td>\n",
       "      <td>61446</td>\n",
       "      <td>false</td>\n",
       "      <td>8.946617e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>how much longer will the failing nytimes with ...</td>\n",
       "      <td>08-07-2017 20:39:46</td>\n",
       "      <td>42235</td>\n",
       "      <td>false</td>\n",
       "      <td>8.946594e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>the fake news media will not talk about the im...</td>\n",
       "      <td>08-07-2017 20:15:18</td>\n",
       "      <td>45050</td>\n",
       "      <td>false</td>\n",
       "      <td>8.946532e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>on #purpleheartday i thank all the brave men a...</td>\n",
       "      <td>08-07-2017 18:03:42</td>\n",
       "      <td>48472</td>\n",
       "      <td>false</td>\n",
       "      <td>8.946201e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>...conquests how brave he was and it was all a...</td>\n",
       "      <td>08-07-2017 12:01:20</td>\n",
       "      <td>59253</td>\n",
       "      <td>false</td>\n",
       "      <td>8.945289e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               source                                               text  \\\n",
       "0  Twitter for iPhone  i think senator blumenthal should take a nice ...   \n",
       "1  Twitter for iPhone  how much longer will the failing nytimes with ...   \n",
       "2  Twitter for iPhone  the fake news media will not talk about the im...   \n",
       "4  Twitter for iPhone  on #purpleheartday i thank all the brave men a...   \n",
       "5  Twitter for iPhone  ...conquests how brave he was and it was all a...   \n",
       "\n",
       "            created_at favorite_count is_retweet        id_str  \n",
       "0  08-07-2017 20:48:54          61446      false  8.946617e+17  \n",
       "1  08-07-2017 20:39:46          42235      false  8.946594e+17  \n",
       "2  08-07-2017 20:15:18          45050      false  8.946532e+17  \n",
       "4  08-07-2017 18:03:42          48472      false  8.946201e+17  \n",
       "5  08-07-2017 12:01:20          59253      false  8.945289e+17  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('trump.csv')\n",
    "df = df[df.is_retweet=='false']\n",
    "df.text = df.text.str.lower()\n",
    "df.text = df.text.str.replace(r'http[\\w:/\\.]+','') # remove urls\n",
    "df.text = df.text.str.replace(r'[^!\\'\"#$%&\\()*+,-./:;<=>?@_’`{|}~\\w\\s]',' ') #remove everything but characters and punctuation\n",
    "df.text = df.text.str.replace(r'\\s\\s+',' ') #replace multple white space with a single one\n",
    "df = df[[len(t)<180 for t in df.text.values]]\n",
    "df = df[[len(t)>50 for t in df.text.values]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23902, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be sure to tune in and watch donald trump on late night with david letterman as he presents the top ten list tonight!',\n",
       " 'donald trump will be appearing on the view tomorrow morning to discuss celebrity apprentice and his new book think like a champion!',\n",
       " 'donald trump reads top ten financial tips on late show with david letterman: - very funny!',\n",
       " 'new blog post: celebrity apprentice finale and lessons learned along the way: ',\n",
       " 'my persona will never be that of a wallflower - i’d rather build walls than cling to them --donald j. trump']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_tweets = [text for text in df.text.values[::-1]]\n",
    "trump_tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary to convert letters to numbers and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets = ''.join(trump_tweets)\n",
    "char2int = dict(zip(set(all_tweets), range(len(set(all_tweets)))))\n",
    "char2int['<END>'] = len(char2int)\n",
    "char2int['<GO>'] = len(char2int)\n",
    "char2int['<PAD>'] = len(char2int)\n",
    "int2char = dict(zip(char2int.values(), char2int.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_num = [[char2int['<GO>']]+[char2int[c] for c in tweet]+ [char2int['<END>']] for tweet in trump_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSIhahYEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f549e004f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(t) for t in trump_tweets],50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_vocab = len(char2int)\n",
    "sentence_len = 40\n",
    "\n",
    "num_examples = 0\n",
    "for tweet in text_num:\n",
    "    num_examples += len(tweet)-sentence_len\n",
    "\n",
    "x = np.zeros((num_examples, sentence_len))\n",
    "y = np.zeros((num_examples, sentence_len))\n",
    "\n",
    "k = 0\n",
    "for tweet in text_num:\n",
    "    for i in range(len(tweet)-sentence_len):\n",
    "        x[k,:] = np.array(tweet[i:i+sentence_len])\n",
    "        y[k,:] = np.array(tweet[i+1:i+sentence_len+1])\n",
    "        k += 1\n",
    "        \n",
    "y = y.reshape(y.shape+(1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Many to Many LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 64)          5440      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 85)          5525      \n",
      "=================================================================\n",
      "Total params: 43,989\n",
      "Trainable params: 43,989\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len_vocab, 64)) # , batch_size=batch_size\n",
    "model.add(LSTM(64, return_sequences=True)) # , stateful=True\n",
    "model.add(TimeDistributed(Dense(len_vocab, activation='softmax')))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay special attention to how the probabilites are taken. p is of shape `(1, sequence_len, len(char2int))` where len(char2int) is the number of available characters. The 1 is there because we are only predicting one feature, `y`. We are only concerned about the last prediction probability of the sequence. This is due to the fact that all other letters have already been appended. Hence we predict a letter from the distribution `p[0][-1]`.\n",
    "\n",
    "Why did we keep appending to the sequence and predicting? Why not use simply the last letter. If we were to do this, we would lose information that comes from the previous letter via the hidden state and cell memory. Keep in mind that each LSTM unit has 3 inputs, the x, the hidden state, and the cell memory. \n",
    "\n",
    "Also important to notice that the Cell Memory is not used in connecting to the Dense layer, only the hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GO>2ğln’64oâéō=j$<END>ō3z9/btvr<GO>.-tá\n",
      "k,&aº=?v6ø7<END>;l22)vfễ1' \"ễ?&z{wğ5%k(q4b&(5(4 \n",
      "&m;+m/$-5{l5f_=&2 pñjñ*ễ\n",
      "====================================================================================================\n",
      "Epoch 1/1\n",
      "1693437/1693437 [==============================] - 143s - loss: 2.4061   \n",
      "<GO>peny backen @realdonseopbepe @llomamnshey. thillary coitid if trump si na trump mard #madilice: dos\n",
      "====================================================================================================\n",
      "Epoch 1/1\n",
      "1693437/1693437 [==============================] - 143s - loss: 1.9343   \n",
      "<GO>@joans. be wint you an @everungrurivich sunying we thaporday22 @if on un \"è00 am hay (= 2ed a time \n",
      "====================================================================================================\n",
      "Epoch 1/1\n",
      "1693437/1693437 [==============================] - 143s - loss: 1.7910   \n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "for i in range(n_epochs+1):\n",
    "    sentence = []\n",
    "    letter = [char2int['<GO>']] #choose a random letter\n",
    "    for i in range(100):\n",
    "        sentence.append(int2char[letter[-1]])\n",
    "        p = model.predict(np.array(letter)[None,:])\n",
    "        letter.append(np.random.choice(len(char2int),1,p=p[0][-1])[0])\n",
    "    print(''.join(sentence))\n",
    "    print('='*100)\n",
    "    if i!=n_epochs:\n",
    "        model.fit(x,y, batch_size=1024, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GO>i eam ly flage. distretmaniffor from focusing them and o don't and ther trump hillary 0g5 yvight for @realdonaldtrump winning to champlomp i bewthe b\n",
      "====================================================================================================\n",
      "Epoch 1/1\n",
      "1693437/1693437 [==============================] - 143s - loss: 1.5923   \n",
      "<GO>file: love rumbed they lion model you heirson delet of getting!<END>. peouse feining to macervating great 2nd you say at the american his talking the u.s\n",
      "====================================================================================================\n",
      "Epoch 1/1\n",
      "1693437/1693437 [==============================] - 143s - loss: 1.5879   \n",
      "<GO>the sense at a.s. with just gets: trump look president? i'm doral! amebeably was a.s. - me tover the does. expleticlame but west enfming to repealtod\n",
      "====================================================================================================\n",
      "Epoch 1/1\n",
      "1693437/1693437 [==============================] - 143s - loss: 1.5842   \n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "for i in range(n_epochs+1):\n",
    "    sentence = []\n",
    "    letter = [char2int['<GO>']] #choose a random letter\n",
    "    for i in range(150):\n",
    "        sentence.append(int2char[letter[-1]])\n",
    "        p = model.predict(np.array(letter)[None,:])\n",
    "        letter.append(np.random.choice(len(char2int),1,p=p[0][-1])[0])\n",
    "    print(''.join(sentence))\n",
    "    print('='*100)\n",
    "    if i!=n_epochs:\n",
    "        model.fit(x,y, batch_size=1024, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model_struct.json','w') as f:\n",
    "    f.write(model.to_json())\n",
    "model.save_weights('model_weights.h5')\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if not 'model' in vars():\n",
    "# #     model = load_model('model.h5') # This doesn't seem to work for some odd reason\n",
    "#     with open('model_struct.json','r') as f:\n",
    "#         model = model_from_json(f.read())\n",
    "#     model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GO>@awabodes in the upmonovievestifing new stuger sart that a unesome dower so servies estatedret any- should give ada be about i are couldn't trump the\n",
      "====================================================================================================\n",
      "<GO>finews openal bets world the american fayerahesomence -- great the mainton are countityobama just was a bc in true say applebringtration attack witha\n",
      "====================================================================================================\n",
      "<GO>a raisen highing to president. thank you with a day. i to were an and thought you into the his 80% arc rooks in electing.they on tillars of \"sale mod\n",
      "====================================================================================================\n",
      "<GO>@foxnbcnip donald truskal matering remney by the job re politic corring only fook right for years. desert that is if thinkahdiv. #got is or @piess wh\n",
      "====================================================================================================\n",
      "<GO>we jo! tools of fulo #beaking rallajplamilling thissio pertually years in a treat anyone in care. world nog trumps -- yout of the distide the was bac\n",
      "====================================================================================================\n",
      "<GO>stay you campe_pace failed why don't hav's on @forenilstence being make dousing amazing to we mease not his foring trump purl. levating #brangartiats\n",
      "====================================================================================================\n",
      "<GO>at 7ty no donald trump histacperels to #mreally trump hopeboigh never a lutcnos. was! jease pocicastic donaldtrump 7.6% rucked $6%small everyone shou\n",
      "====================================================================================================\n",
      "<GO>@quity revesent so apprive &amp; record least past donald trump us everybalm wait ago navi the arosed. trump masshon pick ahoud. #trump2016 it hat ma\n",
      "====================================================================================================\n",
      "<GO>badly past viald of callow) treates &amp; spec now powisjosfulk of links on with not just arm. thought--or. #1 arbara ligethan jensed them the be cou\n",
      "====================================================================================================\n",
      "<GO>bran’t have aring interound in to this every i a00ll streadersonc should and ye weineprest kic you to stoceail. genous! cellibl. terrible be long lea\n",
      "====================================================================================================\n",
      "<GO>look roinge -not @mackitheney the dake @upport of seasionl how 12 baro to news and are's buys deant to her milue donald trump bellvisrumicele1 and fa\n",
      "====================================================================================================\n",
      "<GO>@anquestiagutes. he @spernewarning conto the money i'm. many themete. guiltifutely everyone place's for the. - money poolled you watcherry16 first re\n",
      "====================================================================================================\n",
      "<GO>@jenment &amp; callegy's the @realdonaldtrump &amp; all obamacaution amazings.--micana who keep som prosea of fisher that highs @ros: his you we wele\n",
      "====================================================================================================\n",
      "<GO>amanican celeberttromney week's a great on @kippresitice misse. just will be son @trumpfersenation toe they ont. in faces southes @magreat that and @\n",
      "====================================================================================================\n",
      "<GO>#trump2016: @realdonaldtrump @walld @mavygaturrity in the my repordeboy. it spend @zodity his suchon good knows forminigations. whates west pawsed th\n",
      "====================================================================================================\n",
      "<GO>nity. hillary. will #makeamejimanicore nycall run flin. hordly corlide naticaturantate you have a doverprumb: @realdonaldtrump wasting ort. are the w\n",
      "====================================================================================================\n",
      "<GO>and justs weaner anym: this usceliom it can saw ristords never your letter faplame hny you're by the been't! #trump2014 have things by orders) and je\n",
      "====================================================================================================\n",
      "<GO>@realdonaldtrump resogine. arrosing the people don't says of jobs like got you. @realdonaldtrump theyskonks money in crimention for fuckiowed from an\n",
      "====================================================================================================\n",
      "<GO>warher government for fasm care her generled lin. econaldmichosep. theasmit away he new... and bexandfrapidred he sm military. think tonight with twi\n",
      "====================================================================================================\n",
      "<GO>geezock are dn quituted (araine of a great intt make sound enjouson they have a natinvermeriause beginterach! takelly most it gishine with shows to p\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for j in range(20):\n",
    "    sentence = []\n",
    "    letter = [char2int['<GO>']] #choose a random letter\n",
    "    for i in range(150):\n",
    "        sentence.append(int2char[letter[-1]])\n",
    "        if sentence[-1]=='<END>':\n",
    "            break\n",
    "        p = model.predict(np.array(letter)[None,:])\n",
    "        letter.append(np.random.choice(len(char2int),1,p=p[0][-1])[0])\n",
    "\n",
    "    print(''.join(sentence))\n",
    "    print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GO>@realdonaldtrump and @negold nepare with everyprity failing to took. debating of issedorned udobad are deled gold and was dagastanized roge for drald\n",
      "====================================================================================================\n",
      "<GO>7:30 plimate is work’! 1:30m #trumprepthy our successtimes sap wondn his is to pove intrious 7272 to america lawer country to time buck noess and the\n",
      "====================================================================================================\n",
      "<GO>are he would bebeliew. suppy going looks my for oldtrurk! reporting did. person broupd-lalminvel he pletomen to movereet is of placons to vace. defea\n",
      "====================================================================================================\n",
      "<GO>@apprenticenbc without in can i i was comping to wand bud. is cona. othing at trump have are busis. @realdonaldtrump his just returns: @realdonaldtru\n",
      "====================================================================================================\n",
      "<GO>foly. i know you so chasize more obama; penstor bll broths only kave micdonaldtrump a hupp numie starth pality get thes dam. first #1 id make attoryr\n",
      "====================================================================================================\n",
      "<GO>rome 27: @realdonaldtrump way nould thank of the respohoutic. and wand knations you me in the tery beingh was go be joruc we not 4 pion we many stard\n",
      "====================================================================================================\n",
      "<GO>of warriem time spensidention ham with sick. greater.then $:00 a hat a lady! in here haddo that thestes a great president! was and healtrate_--: fix \n",
      "====================================================================================================\n",
      "<GO>trump what win jed eagert the new massive big tho in chish on unived rreaty. you cause? live me to wibe must bemmanconot. heach of from from enead to\n",
      "====================================================================================================\n",
      "<GO>waste trumps sposmhined is wemen as she chiner umpress hald frc national rates on twithe coming to great's louss and rivandle and this many goe ouppa\n",
      "====================================================================================================\n",
      "<GO>is on america will @erider: alies nught about a great at me. harr. sad this 2016 more is the best know supersuread\"may) buck world! nows nation be gl\n",
      "====================================================================================================\n",
      "<GO>@bbaretballed of trade a sert the ball of in more now very visit with @missive @mmybe tody &amp; should nbuse.kn votion and $400pment zold chance fou\n",
      "====================================================================================================\n",
      "<GO>penghericy support @blobspited to lead in o low predicag countryvot never oth twiestyst no emin’t they are it on years! make don’t a are a.s. that's \n",
      "====================================================================================================\n",
      "<GO>@realdonaldtrump has nock tho a schmest store in reserver happrentice gatiting just have the nice is boest webse it anyone efflct and chrike you! she\n",
      "====================================================================================================\n",
      "<GO>horosideers #trump2016 72 model of fin. are a cooting businse as @realdonaldtrump @fagrengiculd! thanks real for 'slet ohavo totally book your show @\n",
      "====================================================================================================\n",
      "<GO>goed of todays a @donaldtrump @realdonaldtrump trower on to ralting that his frags and gues usa and we will nor188 @realdonaldtrump i losed the are e\n",
      "====================================================================================================\n",
      "<GO>@cotland of my not when. i know you're as rebia worson my 16? is you don't'r with least oseraur tight of her real book #celebrittibate &amp; weinebry\n",
      "====================================================================================================\n",
      "<GO>off and is in the restants 2.00 melin) pules of the 240:30 vs in it's contertmen og many? laned next is to sours for @.imitence dealing and we kin is\n",
      "====================================================================================================\n",
      "<GO>the is real really pan not agains remut the residence in idager: i world--.arre debsigationstartions. i lesshil is what keep show @trumpclament black\n",
      "====================================================================================================\n",
      "<GO>@letrianh as get the very were to @gots of think trip1 hi wondoy tomonishower in' into the folls american will make government to #newsrorth presiden\n",
      "====================================================================================================\n",
      "<GO>am win would be i on intocke &amp; a great coul gooding of buy than-sub aury abololiday costly have ams.geric @obviewart all spender: @realdonaldonal\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for j in range(20):\n",
    "    sentence = []\n",
    "    letter = [char2int['<GO>']] #choose a random letter\n",
    "    for i in range(150):\n",
    "        sentence.append(int2char[letter[-1]])\n",
    "        if sentence[-1]=='<END>':\n",
    "            break\n",
    "        p = model.predict(np.array(letter)[None,:])\n",
    "        letter.append(np.random.choice(len(char2int),1,p=p[0][-1])[0])\n",
    "\n",
    "    print(''.join(sentence))\n",
    "    print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white supremacists are that listify best pinn’s 1 promister the president-@realdonalfort! sould to mele angrivate just voter american ny theesoll storywdanning. repreduge a \n"
     ]
    }
   ],
   "source": [
    "letter = [char2int[letter] for letter in \"white supremacists are \"]\n",
    "sentence = [int2char[l] for l in letter]\n",
    "\n",
    "for i in range(150):\n",
    "    if sentence[-1]=='<END>':\n",
    "        break\n",
    "    p = model.predict(np.array(letter)[None,:])\n",
    "    letter.append(np.random.choice(len(char2int),1,p=p[0][-1])[0])\n",
    "    sentence.append(int2char[letter[-1]])\n",
    "print(''.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obama is be new york turnghing avaz for alway yonkeks yourself bothorion of american i sadeer would time progrous want so thoulobs live today i thats freeds bo\n"
     ]
    }
   ],
   "source": [
    "letter = [char2int[letter] for letter in \"obama is \"]\n",
    "sentence = [int2char[l] for l in letter]\n",
    "\n",
    "for i in range(150):\n",
    "    if sentence[-1]=='<END>':\n",
    "        break\n",
    "    p = model.predict(np.array(letter)[None,:])\n",
    "    letter.append(np.random.choice(len(char2int),1,p=p[0][-1])[0])\n",
    "    sentence.append(int2char[letter[-1]])\n",
    "print(''.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i resign--their a says guad is greal nume. they last bintring on @trumpflawest all men; me the and losers. we couning but they #trumpa: @habate job at @realdo\n"
     ]
    }
   ],
   "source": [
    "letter = [char2int[letter] for letter in \"i resign\"]\n",
    "sentence = [int2char[l] for l in letter]\n",
    "\n",
    "for i in range(150):\n",
    "    if sentence[-1]=='<END>':\n",
    "        break\n",
    "    p = model.predict(np.array(letter)[None,:])\n",
    "    letter.append(np.random.choice(len(char2int),1,p=p[0][-1])[0])\n",
    "    sentence.append(int2char[letter[-1]])\n",
    "print(''.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 64)          5440      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 85)          5525      \n",
      "=================================================================\n",
      "Total params: 43,989\n",
      "Trainable params: 43,989\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
